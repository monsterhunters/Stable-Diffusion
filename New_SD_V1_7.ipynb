{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monsterhunters/Stable-Diffusion/blob/main/New_SD_V1_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V1.6"
      ],
      "metadata": {
        "id": "7sZJoayTUAkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # **Install** üöÄ\n",
        "# All necessary imports goes here\n",
        "from IPython.display import clear_output, display, HTML\n",
        "import os, subprocess, time, glob\n",
        "import zipfile\n",
        "import shutil\n",
        "from datetime import timedelta\n",
        "from google.colab import drive\n",
        "from IPython.utils import capture\n",
        "from subprocess import getoutput\n",
        "from urllib.parse import unquote\n",
        "from google.colab.output import eval_js\n",
        "%cd /content\n",
        "\n",
        "import time\n",
        "try:\n",
        "  start_colab\n",
        "except:\n",
        "  start_colab = int(time.time())-5\n",
        "\n",
        "print(\"\\033[96m\") #Cyan text\n",
        "# Check if gpu exist, stop if don't.\n",
        "try:\n",
        "  output\n",
        "except:\n",
        "  print('‚åö Checking GPU...', end='')\n",
        "  output = getoutput('nvidia-smi --query-gpu=gpu_name --format=csv')\n",
        "  if \"name\" in output:\n",
        "    gpu_name = output[5:]\n",
        "    print('\\r‚úÖ Current GPU:', gpu_name, flush=True)\n",
        "  else:\n",
        "    print('\\r\\033[91m‚ùé ERROR: No GPU detected. Please do step below to enable.\\n', flush=True)\n",
        "    display(HTML(\"<img src='https://i.ibb.co/HC9KH17/NVIDIA-Share-23-01-02-173037.png' width='800px'/>\"))\n",
        "    print('\\033[91m\\nIf it says \"Cannot connect to GPU backend\", meaning you\\'ve either reached free usage limit. OR there\\'s no gpu available.\\n\\nDon\\'t mind me... I\\'m destroying your current session for your own good...')\n",
        "    display(HTML(\"<img src='https://media.tenor.com/E9omRGF7x0AAAAAC/hitori-gotou-bocchi-rock.gif' width='500px'/>\"))\n",
        "    time.sleep(5)\n",
        "    from google.colab import runtime\n",
        "    runtime.unassign()\n",
        "\n",
        "\n",
        "\n",
        "codemaster_addon = True #@param{type: \"boolean\"}\n",
        "xformers = True #@param{type: \"boolean\"}\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "start_install = int(time.time())\n",
        "\n",
        "def my_function():\n",
        "    # Clone the repository\n",
        "    os.system('git clone https://github.com/monsterhunters/stablecode.git')\n",
        "\n",
        "    # Download and install dependencies\n",
        "    os.system('wget https://huggingface.co/NoCrypt/fast-repo/resolve/main/ubuntu_deps.zip ; unzip ubuntu_deps.zip -d ./deps ; dpkg -i ./deps/* ; rm -rf ubuntu_deps.zip /content/deps/')\n",
        "\n",
        "    # Download files using aria2c\n",
        "    aria_command = (\n",
        "        \"aria2c -i- -j5 -x16 -s16 -k1M -c <<EOF\\n\"\n",
        "        \"https://huggingface.co/NoCrypt/fast-repo/resolve/main/dep.tar.lz4\\n\"\n",
        "        \" out=dep.tar.lz4\\n\"\n",
        "        \"https://huggingface.co/bigbossmonster/ext/resolve/main/ext4.tar.lz4\\n\"\n",
        "        \" out=ext4.tar.lz4\\n\"\n",
        "        \"https://huggingface.co/NoCrypt/fast-repo/resolve/main/cache.tar.lz4\\n\"\n",
        "        \" out=cache.tar.lz4\\n\"\n",
        "        \"https://huggingface.co/bigbossmonster/ext/resolve/main/ext3.tar.lz4\\n\"\n",
        "        \" out=ext3.tar.lz4\\n\"\n",
        "        \"EOF\"\n",
        "    )\n",
        "    os.system(aria_command)\n",
        "    print('Finishing the setup.. ')\n",
        "    # Extract files using tar and lz4\n",
        "    os.system('tar -xI lz4 -f dep.tar.lz4 --overwrite-dir --directory=/usr/local/lib/python3.10/dist-packages/')\n",
        "    os.system('tar -xI lz4 -f ext3.tar.lz4 --overwrite-dir --directory=/content/stablecode/')\n",
        "    os.system('tar -xI lz4 -f ext4.tar.lz4 --overwrite-dir --directory=/content/stablecode/')\n",
        "    os.system('tar -xI lz4 -f cache.tar.lz4 --directory=/')\n",
        "\n",
        "    !wget https://github.com/camenduru/gperftools/releases/download/v1.0/libtcmalloc_minimal.so.4 -O /content/libtcmalloc_minimal.so.4\n",
        "    %env LD_PRELOAD=/content/libtcmalloc_minimal.so.4\n",
        "\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"]='1'\n",
        "    os.environ[\"CUDA_MODULE_LOADING\"]=\"LAZY\"\n",
        "    os.environ[\"colab_url\"] = eval_js(\"google.colab.kernel.proxyPort(7860, {'cache': false})\")\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "    # %env PYTHONDONTWRITEBYTECODE=1\n",
        "    os.environ[\"TCMALLOC_AGGRESSIVE_DECOMMIT\"] = \"t\"\n",
        "    # os.environ['PYTORCH_CUDA_ALLOC_CONF'] = \"garbage_collection_threshold:0.9,max_split_size_mb:512\"\n",
        "    # !apt -y update -qq\n",
        "\n",
        "    # Remove downloaded archive files\n",
        "    os.system('rm -rf /content/dep.tar.lz4 /content/ext3.tar.lz4 /content/ext4.tar.lz4 /content/cache.tar.lz4')\n",
        "    print('Successfully install')\n",
        "\n",
        "\n",
        "\n",
        "# Call the function\n",
        "print('Unpacking.. Please be patient')\n",
        "my_function()\n",
        "\n",
        "#!echo -n {start_colab} > stablecode/static/colabTimer.txt\n",
        "#if not os.path.exists(\"/content/stablecode\"):\n",
        "\n",
        "install_time = timedelta(seconds=time.time()-start_install)\n",
        "print(\"\\rüöÄ Finished unpacking. Took\",\"%02d:%02d:%02d ‚ö°\\n\" % (install_time.seconds / 3600, (install_time.seconds / 60) % 60, install_time.seconds % 60), end='', flush=True)\n",
        "# Colab ü§ù Gradio (Colab timer integration for gradio)\n",
        "!echo -n {start_colab} > /content/stablecode/static/colabTimer.txt\n",
        "print(\"ü§ù Colab timer integration complete! You can see your colab time inside webui.\")\n",
        "\n",
        "\n",
        "\n",
        "if codemaster_addon:\n",
        "\n",
        "\n",
        "  # Function to copy files to the destination directory, checking if they exist already\n",
        "  def copy_files(files, source_directory, destination_directory):\n",
        "      for file in files:\n",
        "          source_file = os.path.join(source_directory, file)\n",
        "          destination_file = os.path.join(destination_directory, file)\n",
        "          os.makedirs(destination_directory, exist_ok=True)  # Create the destination directory if it doesn't exist\n",
        "          shutil.copy2(source_file, destination_file)\n",
        "\n",
        "  def extract_all_zips(wildcards_directory, destination_wildcards_directory):\n",
        "      for file in os.listdir(wildcards_directory):\n",
        "          if file.endswith('.zip'):\n",
        "              file_path = os.path.join(wildcards_directory, file)\n",
        "              with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "                  zip_ref.extractall(destination_wildcards_directory)\n",
        "\n",
        "  # Update the paths and add the necessary steps\n",
        "\n",
        "  folder_path = '/content/stablecode/extensions/Umi-AI-debloat'\n",
        "\n",
        "  if os.path.exists(folder_path):\n",
        "      shutil.rmtree(folder_path)\n",
        "\n",
        "\n",
        "  if not os.path.exists(\"/content/stablecode/extensions/sd-dynamic-prompts\"):\n",
        "      %cd /content/stablecode/extensions\n",
        "      os.system('git clone https://github.com/adieyal/sd-dynamic-prompts.git')\n",
        "\n",
        "  if not os.path.exists(\"/content/stablecode/plugin-for-SD\"):\n",
        "      %cd /content/stablecode\n",
        "      os.system('git clone https://github.com/monsterhunters/plugin-for-SD.git')\n",
        "\n",
        "\n",
        "\n",
        "  scripts_directory = \"/content/stablecode/plugin-for-SD/scripts\"  # Source directory for Python files\n",
        "  wildcards_directory = \"/content/stablecode/plugin-for-SD/wildcards\"  # Source directory for text files\n",
        " # modules_directory = \"/content/stablecode/plugin-for-SD/modules\"  # Source directory for text files\n",
        "  embeddings_directory = \"/content/stablecode/plugin-for-SD/embeddings\"  # Source directory for text files\n",
        "  destination_scripts_directory = \"/content/stablecode/scripts\"  # Destination directory for Python files\n",
        "  destination_wildcards_directory = \"/content/stablecode/extensions/sd-dynamic-prompts/wildcards\"  # Destination directory for text files\n",
        "  destination_modules_directory = \"/content/stablecode/modules\"  # Destination directory for text files\n",
        "  destination_embeddings_directory = \"/content/stablecode/embeddings\"  # Destination directory for text files\n",
        "\n",
        "  # Rest of the code...\n",
        "\n",
        "  # Extract all ZIP files from wildcards_directory\n",
        "  extract_all_zips(wildcards_directory, destination_wildcards_directory)\n",
        "\n",
        "\n",
        "  def copy_files(files, source_directory, destination_directory):\n",
        "      for file in files:\n",
        "          source_file = os.path.join(source_directory, file)\n",
        "          destination_file = os.path.join(destination_directory, file)\n",
        "          os.makedirs(destination_directory, exist_ok=True)  # Create the destination directory if it doesn't exist\n",
        "          shutil.copy2(source_file, destination_file)\n",
        "  # Get a list of all text files and Python files in the scripts directory\n",
        "  script_files = [file for file in os.listdir(scripts_directory) if file.endswith(\".py\")]\n",
        "  # Copy Python files to the destination scripts directory, checking if they exist already\n",
        "  copy_files(script_files, scripts_directory, destination_scripts_directory)\n",
        "  # Get a list of all text files in the wildcards directory\n",
        "  wildcard_files = [file for file in os.listdir(wildcards_directory) if file.endswith(\".txt\")]\n",
        "  # Copy text files to the destination wildcards directory, checking if they exist already\n",
        "  copy_files(wildcard_files, wildcards_directory, destination_wildcards_directory)\n",
        "  # Get a list of all Python files in the modules directory\n",
        "#  module_files = [file for file in os.listdir(modules_directory) if file.endswith(\".py\")]\n",
        "  # Copy Python files to the destination modules directory, checking if they exist already\n",
        "#  copy_files(module_files, modules_directory, destination_modules_directory)\n",
        "\n",
        "  embeddings_files = [file for file in os.listdir(embeddings_directory) if file.endswith((\".pt\", \".bin\"))]\n",
        "  # Copy Python files to the destination modules directory, checking if they exist already\n",
        "  copy_files(embeddings_files, embeddings_directory, destination_embeddings_directory)\n",
        "\n",
        "#!rm rf \"/content/stablecode/extensions/sd-photopea-embed-lazy\"\n",
        "\n",
        "if xformers:\n",
        "  !pip install -q torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 torchtext==0.15.2 torchdata==0.6.1 --extra-index-url https://download.pytorch.org/whl/cu118 -U\n",
        "  !pip install -q xformers==0.0.20 triton==2.0.0 -U\n",
        "  !pip install pyre-extensions==0.0.29\n",
        "\n",
        "\n",
        "shutil.rmtree(\"/content/stablecode/extensions/sd-photopea-embed-lazy\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Tblpez547swM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBE7Po9EQfC3",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title # **RUN** üöÄ\n",
        "!npm install -g localtunnel\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "%cd /content/stablecode\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\\n\")\n",
        "\n",
        "  print(\"The password/enpoint ip for localtunnel is:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "  p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n",
        "  for line in p.stdout:\n",
        "    print(line.decode(), end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(7860,)).start()\n",
        "\n",
        "commandline_arguments = \"--opt-sdp-no-mem-attention --ckpt-dir '/content/drive/Shareddrives/BSSG-RCN-(70)/HTZ/CodeUI/models/checkpoints' --vae-dir '/content/drive/Shareddrives/BSSG-RCN-(70)/HTZ/CodeUI/models/vae' --embeddings-dir '/content/drive/Shareddrives/BSSG-RCN-(70)/HTZ/CodeUI/models/embeddings' --lora-dir '/content/drive/Shareddrives/BSSG-RCN-(70)/HTZ/CodeUI/models/loras' --esrgan-models-path '/content/drive/Shareddrives/BSSG-RCN-(70)/HTZ/CodeUI/models/upscale_models'  --controlnet-dir '/content/drive/Shareddrives/BSSG-RCN-(70)/HTZ/controlnet'\"\n",
        "\n",
        "#!nohup script -c \"python launch.py {commandline_arguments}\" output.log &\n",
        "#!nohup script -c \"python launch.py\n",
        "!python launch.py --listen --xformers --enable-insecure-extension-access --ckpt-dir '/content/drive/Shareddrives/BSSG-RCN-(70)/HTZ/CodeUI/models/checkpoints' --vae-dir '/content/drive/Shareddrives/BSSG-RCN-(70)/HTZ/CodeUI/models/vae' --embeddings-dir '/content/drive/Shareddrives/BSSG-RCN-(70)/HTZ/CodeUI/models/embeddings' --lora-dir '/content/drive/Shareddrives/BSSG-RCN-(70)/HTZ/CodeUI/models/loras' --esrgan-models-path '/content/drive/Shareddrives/BSSG-RCN-(70)/HTZ/CodeUI/models/upscale_models'  --controlnet-dir '/content/drive/Shareddrives/BSSG-RCN-(70)/HTZ/controlnet'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ao2t5h5qG9HD",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @markdown ## Setup environment\n",
        "# @markdown This may take up to 5 minutes\n",
        "\n",
        "\n",
        "%cd /content/stablecode/extensions\n",
        "\n",
        "data_dir = \"/content/data\"  # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "#for extension in extensions:\n",
        "#    if extension.startswith(\"#\"):\n",
        "#        continue\n",
        "#    ! git clone {extension}\n",
        "#    extension_name, _ = os.path.splitext(extension.split(\"/\")[-1])\n",
        "#    if not os.path.isdir(extension_name):\n",
        "#      ! git clone {extension}\n",
        "#    else:\n",
        "#      ! cd {extension_name} && git fetch\n",
        "\n",
        "%cd /content\n",
        "\n",
        "conda_dir = \"/opt/conda\"  # @param{type:\"string\"}\n",
        "conda_bin = os.path.join(conda_dir, \"bin\", \"conda\")\n",
        "\n",
        "if not os.path.exists(conda_bin):\n",
        "    ! curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "    ! chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "    ! bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p {conda_dir}\n",
        "    ! rm Miniconda3-latest-Linux-x86_64.sh\n",
        "\n",
        "\n",
        "install_script = f\"\"\"\n",
        "eval \"$({conda_bin} shell.bash hook)\"\n",
        "cd stablecode\n",
        "python3 -m pip install --upgrade tensorrt triton\n",
        "python -c 'from launch import prepare_environment; prepare_environment()'\n",
        "\"\"\"\n",
        "\n",
        "! {install_script}\n",
        "\n",
        "# @markdown\n",
        "# @markdown ## Optional | Apply low RAM patch\n",
        "apply_lowram_patch = True  # @param {type: \"boolean\"}\n",
        "\n",
        "if apply_lowram_patch:\n",
        "    patches_dir = \"/content/patches\"\n",
        "    os.makedirs(patches_dir, exist_ok=True)\n",
        "    ! cd {patches_dir} && curl -LO https://raw.githubusercontent.com/monsterhunters/colab/main/patches/stablediffusion-lowram.patch\n",
        "    ! cd /content/stablecode/repositories/stable-diffusion-stability-ai && git apply {patches_dir}/stablediffusion-lowram.patch\n",
        "\n",
        "\n",
        "os.environ[\n",
        "    \"LD_LIBRARY_PATH\"\n",
        "] = f\"{os.environ['LD_LIBRARY_PATH']}:/usr/local/envs/automatic/lib\"\n",
        "\n",
        "if os.path.exists(f\"{data_dir}/script.post.sh\"):\n",
        "    ! chmod +x {data_dir}/script.post.sh\n",
        "    ! {data_dir}/script.post.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patches_dir = \"/content/patches/\"\n",
        "\n",
        "merge_in_vram = False #@param {type:\"boolean\"}\n",
        "load_in_vram = False #@param {type:\"boolean\"}\n",
        "ram_patch_for_sd2 = True #@param{type:\"boolean\"}\n",
        "dpmpp_v2 = False #@param{type:\"boolean\"}\n",
        "\n",
        "!wget https://gist.github.com/NoCrypt/6e7331eda3d670c2156852ae5e300a42/raw/e52dac97fcabcb054b5737e0c5188cbc600c6582/DPMPP_2M_V2.patch -P {patches_dir}  -c\n",
        "!wget https://gist.github.com/NoCrypt/6e7331eda3d670c2156852ae5e300a42/raw/e52dac97fcabcb054b5737e0c5188cbc600c6582/idgaf_about_git_ext.patch -P {patches_dir}  -c\n",
        "!wget https://gist.github.com/NoCrypt/6e7331eda3d670c2156852ae5e300a42/raw/e52dac97fcabcb054b5737e0c5188cbc600c6582/sd-lowram.patch -P {patches_dir}  -c\n",
        "\n",
        "if ram_patch_for_sd2:\n",
        "  !cd /content/stablecode/ && git apply --ignore-whitespace {patches_dir}/sd-lowram.patch\n",
        "else:\n",
        "  !cd /content/stablecode/ && git apply --ignore-whitespace -R {patches_dir}/sd-lowram.patch\n",
        "\n",
        "if dpmpp_v2:\n",
        "  !cd /content/stablecode/ && git apply --ignore-whitespace {patches_dir}/DPMPP_2M_V2.patch\n",
        "else:\n",
        "  !cd /content/stablecode/ && git apply --ignore-whitespace -R {patches_dir}/DPMPP_2M_V2.patch\n",
        "# IGAF, get lost git ext checker thingy\n",
        "!cd /content/stablecode/ && git apply --ignore-whitespace {patches_dir}/idgaf_about_git_ext.patch\n",
        "# Colab Optimizations modified to load_in_vram\n",
        "\n",
        "if load_in_vram:\n",
        "  commandline_arguments += ' --lowram '\n",
        "# Merge in vram: self-explainotory\n",
        "\n",
        "if merge_in_vram:\n",
        "  !sed -i \"s@'cpu'@'cuda'@\" /content/stablecode/modules/extras.py\n",
        "else:\n",
        "  !sed -i \"s@'cuda'@'cpu'@\" /content/stablecode/modules/extras.py\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KoPXunGnqJxQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}