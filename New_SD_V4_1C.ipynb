{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monsterhunters/Stable-Diffusion/blob/main/New_SD_V4_1C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V4"
      ],
      "metadata": {
        "id": "7sZJoayTUAkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # **Install** üöÄ\n",
        "# All necessary imports goes here\n",
        "from IPython.display import clear_output, display, HTML\n",
        "import os, subprocess, time, glob, sys\n",
        "import zipfile\n",
        "import shutil\n",
        "import requests\n",
        "import importlib.util\n",
        "from datetime import timedelta\n",
        "from google.colab import drive\n",
        "from IPython.utils import capture\n",
        "from subprocess import getoutput\n",
        "from urllib.parse import unquote\n",
        "from google.colab.output import eval_js\n",
        "\n",
        "\n",
        "\n",
        "%cd /content\n",
        "\n",
        "import time\n",
        "try:\n",
        "  start_colab\n",
        "except:\n",
        "  start_colab = int(time.time())-5\n",
        "\n",
        "print(\"\\033[96m\") #Cyan text\n",
        "# Check if gpu exist, stop if don't.\n",
        "#try:\n",
        "#  output\n",
        "#except:\n",
        "#  print('‚åö Checking GPU...', end='')\n",
        "#  output = getoutput('nvidia-smi --query-gpu=gpu_name --format=csv')\n",
        "#  if \"name\" in output:\n",
        "#    gpu_name = output[5:]\n",
        "#    print('\\r‚úÖ Current GPU:', gpu_name, flush=True)\n",
        "#  else:\n",
        "#    print('\\r\\033[91m‚ùé ERROR: No GPU detected. Please do step below to enable.\\n', flush=True)\n",
        "#    display(HTML(\"<img src='https://i.ibb.co/HC9KH17/NVIDIA-Share-23-01-02-173037.png' width='800px'/>\"))\n",
        "#    print('\\033[91m\\nIf it says \"Cannot connect to GPU backend\", meaning you\\'ve either reached free usage limit. OR there\\'s no gpu available.\\n\\nDon\\'t mind me... I\\'m destroying your current session for your own good...')\n",
        "#    display(HTML(\"<img src='https://media.tenor.com/E9omRGF7x0AAAAAC/hitori-gotou-bocchi-rock.gif' width='500px'/>\"))\n",
        "#    time.sleep(5)\n",
        "#    from google.colab import runtime\n",
        "#    runtime.unassign()\n",
        "\n",
        "\n",
        "\n",
        "codemaster_addon = True #@param{type: \"boolean\"}\n",
        "install_Extension = \"min_extension\" # @param [\"none\",\"min_extension\", \"partial_extension\", \"full_extension\", \"full+training\"]\n",
        "Dynamic_Prompts = \"Dynamic-Prompts\" # @param [\"UmiAI\", \"Dynamic-Prompts\"]\n",
        "\n",
        "\n",
        "\n",
        "AnimateDiff = False #@param{type: \"boolean\"}\n",
        "text2Video = False #@param{type: \"boolean\"}\n",
        "Deforum = False #@param{type: \"boolean\"}\n",
        "\n",
        "\n",
        "#import custom\n",
        "url = 'https://raw.githubusercontent.com/monsterhunters/stablecode/refs/heads/master/custom.py'\n",
        "\n",
        "# Download the file\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "    # Save the file locally\n",
        "    file_name = 'custom.py'\n",
        "    with open(file_name, 'w') as file:\n",
        "        file.write(response.text)\n",
        "\n",
        "    # Dynamically import the module\n",
        "    spec = importlib.util.spec_from_file_location(\"custom\", os.path.abspath(file_name))\n",
        "    custom = importlib.util.module_from_spec(spec)\n",
        "    sys.modules[\"custom\"] = custom\n",
        "    spec.loader.exec_module(custom)\n",
        "\n",
        "\n",
        "else:\n",
        "    print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
        "#-END-\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "start_install = int(time.time())\n",
        "\n",
        "#!pip uninstall torch -y\n",
        "def my_function():\n",
        "    os.system('git clone https://github.com/monsterhunters/stablecode.git')\n",
        "    os.system('wget https://huggingface.co/NoCrypt/fast-repo/resolve/main/ubuntu_deps.zip ; unzip ubuntu_deps.zip -d ./deps ; dpkg -i ./deps/* ; rm -rf ubuntu_deps.zip /content/deps/')\n",
        "    aria_command = (\n",
        "        \"aria2c -i- -j5 -x16 -s16 -k1M -c <<EOF\\n\"\n",
        "        \"https://huggingface.co/NoCrypt/fast-repo/resolve/main/dep.tar.lz4\\n\"\n",
        "        \" out=dep.tar.lz4\\n\"\n",
        "        \"https://huggingface.co/bigbossmonster/ext/resolve/main/embbed.tar.lz4\\n\"\n",
        "        \" out=embbed.tar.lz4\\n\"\n",
        "        \"https://huggingface.co/NoCrypt/fast-repo/resolve/main/cache.tar.lz4\\n\"\n",
        "        \" out=cache.tar.lz4\\n\"\n",
        "        \"EOF\"\n",
        "    )\n",
        "    os.system(aria_command)\n",
        "    print('Finishing the setup.. ')\n",
        "    os.system('tar -xI lz4 -f dep.tar.lz4 --overwrite-dir --directory=/usr/local/lib/python3.10/dist-packages/')\n",
        "    os.system('tar -xI lz4 -f embbed.tar.lz4 --overwrite-dir --directory=/content/stable-diffusion-webui-forge/embeddings')\n",
        "    os.system('tar -xI lz4 -f cache.tar.lz4 --directory=/')\n",
        "    os.system('rm -rf /content/dep.tar.lz4 /content/embbed.tar.lz4 /content/cache.tar.lz4')\n",
        "    print('Successfully install')\n",
        "\n",
        "# Call the function\n",
        "print('Unpacking.. Please be patient')\n",
        "my_function()\n",
        "\n",
        "print('optimizing')\n",
        "with capture.capture_output() as cap:\n",
        "\n",
        "    !wget https://github.com/camenduru/gperftools/releases/download/v1.0/libtcmalloc_minimal.so.4 -O /content/libtcmalloc_minimal.so.4\n",
        "    %env LD_PRELOAD=/content/libtcmalloc_minimal.so.4\n",
        "\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"]='1'\n",
        "    os.environ[\"CUDA_MODULE_LOADING\"]=\"LAZY\"\n",
        "    os.environ[\"colab_url\"] = eval_js(\"google.colab.kernel.proxyPort(7860, {'cache': false})\")\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "\n",
        "    !wget https://github.com/cloudflare/cloudflared/releases/download/2024.5.0/cloudflared-fips-linux-amd64.deb\n",
        "    !dpkg -i cloudflared-fips-linux-amd64.deb\n",
        "    !apt-get install -f\n",
        "    !cloudflared --version\n",
        "    !mv /usr/local/bin/cloudflared /usr/local/bin/wex\n",
        "    !pip install insightface==0.7.3 ultralytics dynamicprompts thop mediapipe onnxruntime-gpu\n",
        "    !pip install torchaudio==2.5.1+cu124 --index-url https://download.pytorch.org/whl/cu124\n",
        "    !pip install -q xformers==0.0.28.post2\n",
        "\n",
        "#@title # **Extension** üöÄ\n",
        "def installExtension():\n",
        "\n",
        "    def downloadModel(url):\n",
        "      if 'huggingface.co' in url:\n",
        "        filename = url.split('/')[-1]\n",
        "        filename = filename.removesuffix('?download=true')\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {url}  -o {filename}\n",
        "      else:\n",
        "        # civitai\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {url}\n",
        "\n",
        "\n",
        "    if AnimateDiff:\n",
        "        %cd /content/stablecode/extensions\n",
        "        custom.installAnimateDiff()\n",
        "        %cd sd-webui-animatediff/model\n",
        "        downloadModel('https://huggingface.co/guoyww/animatediff/resolve/main/mm_sd_v14.ckpt')\n",
        "        downloadModel('https://huggingface.co/guoyww/animatediff/resolve/main/mm_sd_v15.ckpt')\n",
        "        downloadModel('https://huggingface.co/guoyww/animatediff/resolve/main/mm_sd_v15_v2.ckpt')\n",
        "\n",
        "    if text2Video:\n",
        "        %cd /content/stablecode/extensions\n",
        "        custom.installtext2video()\n",
        "        %mkdir -p {root}/stablecode/models/text2video/t2v\n",
        "        %cd {root}/stablecode/models/text2video/t2v\n",
        "        downloadModel('https://huggingface.co/damo-vilab/modelscope-damo-text-to-video-synthesis/resolve/main/VQGAN_autoencoder.pth')\n",
        "        downloadModel('https://huggingface.co/damo-vilab/modelscope-damo-text-to-video-synthesis/resolve/main/configuration.json')\n",
        "        downloadModel('https://huggingface.co/damo-vilab/modelscope-damo-text-to-video-synthesis/resolve/main/open_clip_pytorch_model.bin')\n",
        "        downloadModel('https://huggingface.co/damo-vilab/modelscope-damo-text-to-video-synthesis/resolve/main/text2video_pytorch_model.pth')\n",
        "\n",
        "    if Deforum:\n",
        "        %cd /content/stablecode/extensions\n",
        "        custom.installDeforum()\n",
        "\n",
        "def min_extension():\n",
        "    %cd /content/stablecode/extensions\n",
        "    installExtension()\n",
        "    custom.locon()\n",
        "    custom.llul()\n",
        "    custom.ControlNet()\n",
        "    custom.freeU()\n",
        "    custom.installAdetailer()\n",
        "    custom.downloader()\n",
        "    custom.installExtB()\n",
        "\n",
        "def partial_extension():\n",
        "    min_extension()\n",
        "    custom.installExtA()\n",
        "\n",
        "def full_extension():\n",
        "    partial_extension()\n",
        "    custom.installMultidiffusion()\n",
        "    custom.installAdditionalnetworks()\n",
        "    custom.installReactor()\n",
        "    custom.highRes()\n",
        "    custom.twoShot()\n",
        "    custom.composableLora()\n",
        "    custom.removeBg()\n",
        "    custom.umiAI()\n",
        "    custom.easyPhoto()\n",
        "    custom.layerDiffusion()\n",
        "    custom.installRoop()\n",
        "    custom.installFacechain()\n",
        "    custom.installSadtalker()\n",
        "    custom.inpaintAnything()\n",
        "\n",
        "def training_extension():\n",
        "    custom.installDreambooth()\n",
        "\n",
        "if Dynamic_Prompts == \"UmiAI\":\n",
        "    custom.installumiAI()\n",
        "\n",
        "else:\n",
        "    custom.installDPrompts()\n",
        "\n",
        "if codemaster_addon:\n",
        "\n",
        "    # Function to copy files to the destination directory, checking if they exist already\n",
        "    def copy_files(files, source_directory, destination_directory):\n",
        "        os.makedirs(destination_directory, exist_ok=True)  # Create destination directory if it doesn't exist\n",
        "        for file in files:\n",
        "            source_file = os.path.join(source_directory, file)\n",
        "            destination_file = os.path.join(destination_directory, file)\n",
        "            if not os.path.exists(destination_file):\n",
        "                shutil.copy2(source_file, destination_file)\n",
        "\n",
        "    # Function to extract all ZIP files in a directory\n",
        "    def extract_all_zips(source_directory, destination_directory):\n",
        "        os.makedirs(destination_directory, exist_ok=True)  # Ensure the destination exists\n",
        "        for file in os.listdir(source_directory):\n",
        "            if file.endswith('.zip'):\n",
        "                file_path = os.path.join(source_directory, file)\n",
        "                with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "                    zip_ref.extractall(destination_directory)\n",
        "\n",
        "    # Clone the repository if it doesn't exist\n",
        "    if not os.path.exists(\"/content/stablecode\"):\n",
        "        os.mkdir(\"/content/stablecode\")\n",
        "    if not os.path.exists(\"/content/stablecode/plugin-for-SD\"):\n",
        "        os.chdir(\"/content/stablecode\")\n",
        "        os.system('git clone https://github.com/monsterhunters/plugin-for-SD.git')\n",
        "\n",
        "    # Define directories\n",
        "    root_dir = \"/content/stablecode/\"\n",
        "    scripts_directory = os.path.join(root_dir, \"plugin-for-SD/scripts\")\n",
        "    wildcards_directory = os.path.join(root_dir, \"plugin-for-SD/wildcards\")\n",
        "    embeddings_directory = os.path.join(root_dir, \"plugin-for-SD/embeddings\")\n",
        "    destination_scripts_directory = os.path.join(root_dir, \"scripts\")\n",
        "    if Dynamic_Prompts == \"UmiAI\":\n",
        "        destination_wildcards_directory = os.path.join(root_dir, \"extensions/Umi-AI-Embeds/wildcards\")\n",
        "    else:\n",
        "        destination_wildcards_directory = os.path.join(root_dir, \"extensions/sd-dynamic-prompts/wildcards\")\n",
        "    destination_embeddings_directory = os.path.join(root_dir, \"embeddings\")\n",
        "\n",
        "    extract_all_zips(wildcards_directory, destination_wildcards_directory)\n",
        "\n",
        "    script_files = [file for file in os.listdir(scripts_directory) if file.endswith(\".py\")]\n",
        "    copy_files(script_files, scripts_directory, destination_scripts_directory)\n",
        "\n",
        "    wildcard_files = [file for file in os.listdir(wildcards_directory) if file.endswith(\".txt\")]\n",
        "    copy_files(wildcard_files, wildcards_directory, destination_wildcards_directory)\n",
        "\n",
        "    embeddings_files = [file for file in os.listdir(embeddings_directory) if file.endswith((\".pt\", \".bin\"))]\n",
        "    copy_files(embeddings_files, embeddings_directory, destination_embeddings_directory)\n",
        "\n",
        "\n",
        "    if os.path.exists(\"plugin-for-SD\"):\n",
        "          shutil.rmtree(\"plugin-for-SD\")\n",
        "\n",
        "if install_Extension==\"min_extension\":\n",
        "  min_extension()\n",
        "elif install_Extension==\"partial_extension\":\n",
        "  partial_extension()\n",
        "elif install_Extension==\"full_extension\":\n",
        "  full_extension()\n",
        "elif install_Extension==\"full+training\":\n",
        "  full_extension()\n",
        "  training_extension()\n",
        "else:\n",
        "  installExtension()\n",
        "os.chdir('../')\n",
        "\n",
        "\n",
        "install_time = timedelta(seconds=time.time()-start_install)\n",
        "print(\"\\rüöÄ Finished unpacking. Took\",\"%02d:%02d:%02d ‚ö°\\n\" % (install_time.seconds / 3600, (install_time.seconds / 60) % 60, install_time.seconds % 60), end='', flush=True)\n",
        "# Colab ü§ù Gradio (Colab timer integration for gradio)\n",
        "!echo -n {start_colab} > /content/stablecode/static/colabTimer.txt\n",
        "print(\"ü§ù Colab timer integration complete! You can see your colab time inside webui.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pgE_OS_eP6fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary library\n",
        "!pip install huggingface_hub\n",
        "\n",
        "# Import necessary functions from huggingface_hub\n",
        "from huggingface_hub import snapshot_download, login\n",
        "import os\n",
        "\n",
        "# Authenticate with Hugging Face Hub\n",
        "login(token=\"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\")\n",
        "\n",
        "# Set paths for LORA, VAE, and Upscale models\n",
        "lora_path = \"/content/lora\" # @param {type:\"string\"}\n",
        "vae_path = \"/content/vae\" # @param {type:\"string\"}\n",
        "upscale_path = \"/content/upscale\" # @param {type:\"string\"}\n",
        "\n",
        "# Create directories if they do not exist\n",
        "os.makedirs(lora_path, exist_ok=True)\n",
        "os.makedirs(vae_path, exist_ok=True)\n",
        "os.makedirs(upscale_path, exist_ok=True)\n",
        "\n",
        "# Repository IDs for the models\n",
        "lora_repo_id = \"bigbossmonster/lora\"  # Replace with actual LORA repo ID\n",
        "vae_repo_id = \"bigbossmonster/vae\"    # Replace with actual VAE repo ID\n",
        "upscale_repo_id = \"bigbossmonster/upscale\"  # Replace with actual Upscale repo ID\n",
        "\n",
        "# Download the repositories\n",
        "snapshot_download(repo_id=lora_repo_id, local_dir=lora_path)\n",
        "snapshot_download(repo_id=vae_repo_id, local_dir=vae_path)\n",
        "snapshot_download(repo_id=upscale_repo_id, local_dir=upscale_path)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "46RwKimzilX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # **RUN** üöÄ\n",
        "model_path = \"/content/model\" # @param {type:\"string\"}\n",
        "vae_path = \"/content/vae\" # @param {type:\"string\"}\n",
        "lora_path = \"/content/lora\" # @param {type:\"string\"}\n",
        "upscaler_path = \"/content/upscale\" # @param {type:\"string\"}\n",
        "controlnet_path = \"\" # @param {type:\"string\"}\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nUI finished loading, trying to launch (if it gets stuck here  is having issues)\\n\")\n",
        "\n",
        "  p = subprocess.Popen([\"wex\", \"tunnel\", \"--url\", \"http://127.0.0.1:{}\".format(port)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  for line in p.stderr:\n",
        "    l = line.decode()\n",
        "    if \"trycloudflare.com \" in l:\n",
        "      print(\"This is the URL to access UI:\", l[l.find(\"http\"):], end='')\n",
        "    #print(l, end='')\n",
        "\n",
        "args = []\n",
        "\n",
        "if model_path != \"\":\n",
        "    args.append(f\"--ckpt-dir {model_path}\")\n",
        "if vae_path != \"\":\n",
        "    args.append(f\"--vae-dir {vae_path}\")\n",
        "if lora_path != \"\":\n",
        "    args.append(f\"--lora-dir {lora_path}\")\n",
        "if upscaler_path != \"\":\n",
        "    args.append(f\"--esrgan-models-path {upscaler_path}\")\n",
        "if controlnet_path != \"\":\n",
        "    args.append(f\"--controlnet-dir {controlnet_path}\")\n",
        "\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(7860,)).start()\n",
        "\n",
        "!python launch.py --enable-insecure-extension-access --disable-safe-unpickle --no-hashing --xformers {\" \".join(args)}\n",
        "\n",
        "#!python launch.py  --enable-insecure-extension-access --disable-safe-unpickle --no-hashing --xformers\n",
        "#!python launch.py  --enable-insecure-extension-access --disable-safe-unpickle --no-hashing --xformers  --ckpt-dir $model_path --vae-dir $vae_path --lora-dir $lora_path --esrgan-models-path $upscaler_path  --controlnet-dir $controlnet_path\n",
        "#!python launch.py  --no-half-vae --listen --xformers --opt-sdp-no-mem-attention  --ckpt-dir '/content/drive/Shareddrives/BSSG-RCN-(70)/HTZ/CodeUI/models/checkpoints' --vae-dir '/content/drive/Shareddrives/BSSG-RCN-(70)/HTZ/CodeUI/models/vae' --embeddings-dir '/content/drive/Shareddrives/BSSG-RCN-(70)/HTZ/CodeUI/models/embeddings' --lora-dir '/content/drive/Shareddrives/BSSG-RCN-(70)/HTZ/CodeUI/models/loras' --esrgan-models-path '/content/drive/Shareddrives/BSSG-RCN-(70)/HTZ/CodeUI/models/upscale_models'  --controlnet-dir '/content/drive/Shareddrives/BSSG-RCN-(70)/HTZ/controlnet'"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GnKCGCT3RDrT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}